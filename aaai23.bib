@article{gaunt_2020,
  author={Gaunt, David},
  title={The Long Assyrian Genocide},
  DOI={10.2307/j.ctv29sfvw6.6},
  journal={Collective and State Violence in Turkey},
  year={2020},
  pages={56–96}
}
@misc{uscirf,
  author={Mohy Omer},
  title={{Religious Freedom in Iraq in 2021}},
  year = 2022,
  url={https://www.uscirf.gov/sites/default/files/2022-03/2022%20Iraq%20Country%20Update.pdf},
  address = "Washington, DC",
  publisher = "The United States Commission on International Religious Freedom",
}
@book{moseley_nicolas_2010, 
  place={Paris},
  title={Atlas of the world's languages in Danger},
  publisher={UNESCO Pub.},
  author={Moseley, Christopher and Nicolas, Alexander},
  year={2010}
}
@book{commonvoice,
  doi = {10.48550/ARXIV.1912.06670},
  url = {https://arxiv.org/abs/1912.06670},
  author = {Ardila, Rosana and Branson, Megan and Davis, Kelly and Henretty, Michael and Kohler, Michael and Meyer, Josh and Morais, Reuben and Saunders, Lindsay and Tyers, Francis M. and Weber, Gregor},
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Common Voice: A Massively-Multilingual Speech Corpus},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@article{lrspeech,
  doi = {10.48550/ARXIV.2008.03687},
  url = {https://arxiv.org/abs/2008.03687},
  author = {Xu, Jin and Tan, Xu and Ren, Yi and Qin, Tao and Li, Jian and Zhao, Sheng and Liu, Tie-Yan},
  keywords = {Audio and Speech Processing (eess.AS), Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {LRSpeech: Extremely Low-Resource Speech Synthesis and Recognition},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@article{cahill2008factors,
  title={Factors in designing effective orthographies for unwritten languages},
  author={Cahill, Michael and Karan, Elke},
  journal={SIL International},
  year={2008}
}
@inproceedings{khare2021low,
  title={Low Resource ASR: The Surprising Effectiveness of High Resource Transliteration.},
  author={Khare, Shreya and Mittal, Ashish R and Diwan, Anuj and Sarawagi, Sunita and Jyothi, Preethi and Bharadwaj, Samarth},
  booktitle={Interspeech},
  pages={1529--1533},
  year={2021}
}
@inproceedings{9414478,
  author={Feng, Siyuan and Żelasko, Piotr and Moro-Velázquez, Laureano and Abavisani, Ali and Hasegawa-Johnson, Mark and Scharenborg, Odette and Dehak, Najim},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={How Phonotactics Affect Multilingual and Zero-Shot ASR Performance}, 
  year={2021},
  volume={},
  number={},
  pages={7238-7242},
  doi={10.1109/ICASSP39728.2021.9414478}
}
@book{khan2016neo,
  title={{The Neo-Aramaic Dialect of the Assyrian Christians of Urmi (4 vols)}},
  author={Khan, Geoffrey},
  year={2016},
  publisher={Brill}
}
@article{mclaughlin1989sociolinguistics,
  title={The sociolinguistics of Navajo literacy},
  author={McLaughlin, Daniel},
  journal={Anthropology \& Education Quarterly},
  pages={275--290},
  year={1989},
  publisher={JSTOR}
}
@article{venezky2004search,
  title={In search of the perfect orthography},
  author={Venezky, Richard L},
  journal={Written Language \& Literacy},
  volume={7},
  number={2},
  pages={139--163},
  year={2004},
  publisher={John Benjamins}
}
@article{pike1971phonemics,
  title={Phonemics: A technique for reducing languages to writing.},
  author={Pike, Kenneth L},
  year={1971},
  publisher={ERIC}
}
@article{malik2021automatic,
  title={Automatic speech recognition: a survey},
  author={Malik, Mishaim and Malik, Muhammad Kamran and Mehmood, Khawar and Makhdoom, Imran},
  journal={Multimedia Tools and Applications},
  volume={80},
  number={6},
  pages={9411--9457},
  year={2021},
  publisher={Springer}
}
@misc{wav2vec,
  doi = {10.48550/ARXIV.2006.11477},
  url = {https://arxiv.org/abs/2006.11477},
  author = {Baevski, Alexei and Zhou, Henry and Mohamed, Abdelrahman and Auli, Michael},
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), Sound (cs.SD), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  title = {wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@article{chen2021exploring,
  title={Exploring Wav2vec 2.0 fine-tuning for improved speech emotion recognition},
  author={Chen, Li-Wei and Rudnicky, Alexander},
  journal={arXiv preprint arXiv:2110.06309},
  year={2021}
}
@book{Graves2012,
author="Graves, Alex",
title="Connectionist Temporal Classification",
bookTitle="Supervised Sequence Labelling with Recurrent Neural Networks",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="61--93",
abstract="This chapter introduces the connectionist temporal classification (CTC) output layer for recurrent neural networks (Graves et al., 2006). As its name suggests, CTC was specifically designed for temporal classification tasks; that is, for sequence labelling problems where the alignment between the inputs and the target labels is unknown. Unlike the hybrid approach described in the previous chapter, CTC models all aspects of the sequence with a single neural network, and does not require the network to be combined with a hidden Markov model. It also does not require presegmented training data, or external postprocessing to extract the label sequence from the network outputs. Experiments on speech and handwriting recognition show that a BLSTM network with a CTC output layer is an effective sequence labeller, generally outperforming standardHMMsandHMM-neural network hybrids, as well asmore recent sequence labelling algorithms such as large margin HMMs (Sha and Saul, 2006) and conditional random fields (Lafferty et al., 2001).",
isbn="978-3-642-24797-2",
doi="10.1007/978-3-642-24797-2_7",
url="https://doi.org/10.1007/978-3-642-24797-2_7"
}
@article{jiatong,
author = {Jiatong Shi and Jonathan D. Amith and Rey Castillo García and Esteban Guadalupe Sierra and Kevin Duh and Shinji Watanabe},
title = {Leveraging End-to-End ASR for Endangered Language Documentation: An Empirical Study on Yoloxóchitl Mixtec},
year = {2021},
eprint = {arXiv:2101.10877},
}
@misc{flex,
  author = {{SIL International}},
  title = {FLEx},
  year=2007,
  url = {https://software.sil.org/fieldworks/},
}
@misc{saymore,
  author = {{SIL International}},
  title = {SayMore},
  year=2010,
  url = {https://software.sil.org/saymore/},
}
@inproceedings{zahrer-etal-2020-towards,
    title = "Towards Building an Automatic Transcription System for Language Documentation: Experiences from {M}uyu",
    author = "Zahrer, Alexander and Zgank, Andrej and Schuppler, Barbara",
    booktitle = "Proceedings of the Twelfth Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2020.lrec-1.353",
    pages = "2893--2900",
    abstract = "Since at least half of the world{'}s 6000 plus languages will vanish during the 21st century, language documentation has become a rapidly growing field in linguistics. A fundamental challenge for language documentation is the {''}transcription bottleneck{''}. Speech technology may deliver the decisive breakthrough for overcoming the transcription bottleneck. This paper presents first experiments from the development of ASR4LD, a new automatic speech recognition (ASR) based tool for language documentation (LD). The experiments are based on recordings from an ongoing documentation project for the endangered Muyu language in New Guinea. We compare phoneme recognition experiments with American English, Austrian German and Slovenian as source language and Muyu as target language. The Slovenian acoustic models achieve the by far best performance (43.71{\%} PER) in comparison to 57.14{\%} PER with American English, and 89.49{\%} PER with Austrian German. Whereas part of the errors can be explained by phonetic variation, the recording mismatch poses a major problem. On the long term, ASR4LD will not only be an integral part of the ongoing documentation project of Muyu, but will be further developed in order to facilitate also the language documentation process of other language groups.",
    language = "English",
    ISBN = "979-10-95546-34-4",
}
@misc{feng2021,
  doi = {10.48550/ARXIV.2105.03075},
  url = {https://arxiv.org/abs/2105.03075},
  author = {Feng, Steven Y. and Gangal, Varun and Wei, Jason and Chandar, Sarath and Vosoughi, Soroush and Mitamura, Teruko and Hovy, Eduard},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {A Survey of Data Augmentation Approaches for NLP},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@misc{hedderich,
  doi = {10.48550/ARXIV.2010.12309},
  url = {https://arxiv.org/abs/2010.12309},
  author = {Hedderich, Michael A. and Lange, Lukas and Adel, Heike and Strötgen, Jannik and Klakow, Dietrich},
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {A Survey on Recent Approaches for Natural Language Processing in Low-Resource Scenarios},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@misc{ranathunga,
  doi = {10.48550/ARXIV.2106.15115},
  url = {https://arxiv.org/abs/2106.15115},
  author = {Ranathunga, Surangika and Lee, En-Shiun Annie and Skenduli, Marjana Prifti and Shekhar, Ravi and Alam, Mehreen and Kaur, Rishemjit},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences, I.2.7},
  title = {Neural Machine Translation for Low-Resource Languages: A Survey},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@inproceedings{adams-etal-2017-cross,
    title = "Cross-Lingual Word Embeddings for Low-Resource Language Modeling",
    author = "Adams, Oliver  and
      Makarucha, Adam  and
      Neubig, Graham  and
      Bird, Steven  and
      Cohn, Trevor",
    booktitle = "Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/E17-1088",
    pages = "937--947",
    abstract = "Most languages have no established writing system and minimal written records. However, textual data is essential for natural language processing, and particularly important for training language models to support speech recognition. Even in cases where text data is missing, there are some languages for which bilingual lexicons are available, since creating lexicons is a fundamental task of documentary linguistics. We investigate the use of such lexicons to improve language models when textual training data is limited to as few as a thousand sentences. The method involves learning cross-lingual word embeddings as a preliminary step in training monolingual language models. Results across a number of languages show that language models are improved by this pre-training. Application to Yongning Na, a threatened language, highlights challenges in deploying the approach in real low-resource environments.",
}
@misc{nllb,
  doi = {10.48550/ARXIV.2207.04672},
  url = {https://arxiv.org/abs/2207.04672},
  author = {{NLLB Team} and Costa-jussà, Marta R. and Cross, James and Çelebi, Onur and Elbayad, Maha and Heafield, Kenneth and Heffernan, Kevin and Kalbassi, Elahe and Lam, Janice and Licht, Daniel and Maillard, Jean and Sun, Anna and Wang, Skyler and Wenzek, Guillaume and Youngblood, Al and Akula, Bapi and Barrault, Loic and Gonzalez, Gabriel Mejia and Hansanti, Prangthip and Hoffman, John and Jarrett, Semarley and Sadagopan, Kaushik Ram and Rowe, Dirk and Spruit, Shannon and Tran, Chau and Andrews, Pierre and Ayan, Necip Fazil and Bhosale, Shruti and Edunov, Sergey and Fan, Angela and Gao, Cynthia and Goswami, Vedanuj and Guzmán, Francisco and Koehn, Philipp and Mourachko, Alexandre and Ropers, Christophe and Saleem, Safiyyah and Schwenk, Holger and Wang, Jeff},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences, I.2.7, 68T50},
  title = {No Language Left Behind: Scaling Human-Centered Machine Translation},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}


@inproceedings{bosch2000emotions,
  title={Emotions: what is possible in the ASR framework},
  author={Bosch, Louis ten},
  booktitle={ISCA Tutorial and Research Workshop (ITRW) on Speech and Emotion},
  year={2000}
}
@inproceedings{vicsi2006prosodic,
  title={Prosodic cues for automatic phrase boundary detection in ASR},
  author={Vicsi, Kl{\'a}ra and Szasz{\'a}k, Gy{\"o}rgy},
  booktitle={International Conference on Text, Speech and Dialogue},
  pages={547--554},
  year={2006},
  organization={Springer}
}
@article{neyshabur2017exploring,
  title={Exploring generalization in deep learning},
  author={Neyshabur, Behnam and Bhojanapalli, Srinadh and McAllester, David and Srebro, Nati},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}